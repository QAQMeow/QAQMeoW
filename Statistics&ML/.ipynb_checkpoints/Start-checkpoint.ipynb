{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    " **机器学习(machine learning)** 是从数据中提取知识。它是统计学、人工智能和计算机科学交叉的研究领域，也被称为预测分析(predictive analytics)或统计学习(statistical learning)。\n",
    "\n",
    "+ 从输入/输出对中进行学习的机器学习算法叫作 **监督学习算法(supervised learning algorithm)** ，\n",
    "因为每个用于算法学习的样例都对应一个预期输出，好像有一个“老师”在监督着算法。监督机器学习问题主要有两种，分别叫作 **分类(classification)** 与 **回归(regression)** 。分类问题的目标是预测类别标签（class label）。\n",
    "\n",
    "\n",
    "+ **无监督学习算法(unsupervised Learning algorithm)** ，无监督学习包括没有已知输出、没有老师指导学习算法的各种机器学习。在无监督学习中，学习算法只有输入数据，并需要从这些数据中提取知识。\n",
    "+ **聚类算法(clustering algorithm)** 将数据划分成不同的组，每组包含相似的物项。预测各样本之间的关联度，把关联度大的样本划为同一类，关联度小的样本划为不同类。\n",
    "\n",
    "+ **无监督变换(unsupervised transformation)** 是创建数据新的表示的算法，与数据的原始表示相比，新的表示可能更容易被人或其他机器学习算法所理解。无监督变换的一个常见应用是**降维(dimensionality reduction)** 把维度较高、计算复杂的数据，转化为维度低、易处理、且蕴含的信息不丢失或较少丢失的数。\n",
    "\n",
    "+ **增强学习(Reinforcement Learning)** :没有老师(环境)的情况下，计算机对问题答案进行自我评价的方法。\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3>\n",
    "\n",
    "### 衡量模型是否成功：训练数据与测试数据\n",
    "    \n",
    "要用新数据来评估模型的性能。新数据是指模型之前没有见过的数据通常的做法是将收集好的带标\n",
    "签数据分成两部分。一部分数据用于构建机器学习\n",
    "模型，叫作 **训练数据(training data)** 或**训练集(training set)** 。其余的数据用来评估模型性能，叫作**测试数据(test data)** 或**留出集(hold-out set)** 。将预测结果与标签进行对比。我们可以通过计算精度(accuracy)来衡量模型的优劣。如\n",
    "果一个模型能够对没见过的数据做出准确预测，我们就说它能够从训练集泛化(generalize)到测试集。\n",
    "\n",
    "**过拟合(overfitting)** 如果在拟合模型时过分关注训练集的细节，得到了一个在训练\n",
    "集上表现很好、但不能泛化到新数据上的模型，那么就存在过拟合。与之相反，如果你\n",
    "的模型过于简单,无法抓住数据的全部内容以及数据中的变化，模型甚至在训练集上的表现就很差,被称为**欠拟合(underfitting)** 。\n",
    "\n",
    "模型复杂度与训练数据集中输入的变化密切相关：数据集中包含的数据点的变化范围越大，在不发生过拟合的前提下你可以使用的模型就越复杂。通常来说，收集更多的数据点可以有更大的变化范围，所以更大的数据集可以用来构建更复杂的模型。\n",
    "\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-4-27c575294a10>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-27c575294a10>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    过拟合（overfitting）。如果你在拟合模型时过分关注训练集的细节，得到了一个在训练\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-5-9c3550792d79>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-9c3550792d79>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    线性模型是在实践中广泛使用的一类模型，几十年来被广泛研究，它可以追溯到一百多年\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "线性模型是在实践中广泛使用的一类模型，几十年来被广泛研究，它可以追溯到一百多年\n",
    "前。线性模型利用输入特征的线性函数（linear function）进行预测\n",
    "1. 用于回归的线性模型\n",
    "对于回归问题，线性模型预测的一般公式如下：\n",
    "ŷ = w[0] * x[0] + w[1] * x[1] + … + w[p] * x[p] + \n",
    "2. 线性回归（又名普通最小二乘法）\n",
    "线性回归，或者普通最小二乘法（ordinary least squares，OLS），是回归问题最简单也最经\n",
    "典的线性方法。线性回归寻找参数 w 和 b，使得对训练集的预测值与真实的回归目标值 y\n",
    "之间的均方误差最小。均方误差（mean squared error）是预测值与真实值之差的平方和除\n",
    "以样本数。线性回归没有参数，这是一个优点，但也因此无法控制模型的复杂度\n",
    "3. 岭回归\n",
    "岭回归也是一种用于回归的线性模型，因此它的预测公式与普通最小二乘法相同。但在岭\n",
    "回归中，对系数（w）的选择不仅要在训练数据上得到好的预测结果，而且还要拟合附加\n",
    "约束。我们还希望系数尽量小。换句话说，w 的所有元素都应接近于 0。直观上来看，这\n",
    "意味着每个特征对输出的影响应尽可能小（即斜率很小），同时仍给出很好的预测结果。\n",
    "4. lasso\n",
    "除了 Ridge，还有一种正则化的线性回归是 Lasso。与岭回归相同，使用 lasso 也是约束系\n",
    "数使其接近于 0，但用到的方法不同，叫作 L1 正则化。8\n",
    " L1 正则化的结果是，使用 lasso 时\n",
    "某些系数刚好为 0。这说明某些特征被模型完全忽略。这可以看作是一种自动化的特征选\n",
    "择。某些系数刚好为 0，这样模型更容易解释，也可以呈现模型最重要的特征。\n",
    "5. 用于分类的线性模型\n",
    "线性模型也广泛应用于分类问题。我们首先来看二分类。这时可以利用下面的公式进行\n",
    "预测：\n",
    "ŷ = w[0] * x[0] + w[1] * x[1] + …+ w[p] * x[p] + b > 0\n",
    "这个公式看起来与线性回归的公式非常相似，但我们没有返回特征的加权求和，而是为预\n",
    "测设置了阈值（0）。如果函数值小于 0，我们就预测类别 -1；如果函数值大于 0，我们就\n",
    "预测类别 +1。对于所有用于分类的线性模型，这个预测规则都是通用的。同样，有很多种\n",
    "不同的方法来找出系数（w）和截距（b）。\n",
    "对于用于回归的线性模型，输出 ŷ 是特征的线性函数，是直线、平面或超平面（对于更高\n",
    "维的数据集）。对于用于分类的线性模型，决策边界是输入的线性函数。换句话说，（二\n",
    "元）线性分类器是利用直线、平面或超平面来分开两个类别的分类器。本节我们将看到这\n",
    "方面的例子。\n",
    "学习线性模型有很多种算法。这些算法的区别在于以下两点：\n",
    "• 系数和截距的特定组合对训练数据拟合好坏的度量方法；\n",
    "• 是否使用正则化，以及使用哪种正则化方法。\n",
    "不同的算法使用不同的方法来度量“对训练集拟合好坏”。由于数学上的技术原因，不可\n",
    "能调节 w 和 b 使得算法产生的误分类数量最少。对于我们的目的，以及对于许多应用而\n",
    "言，上面第一点（称为损失函数）的选择并不重要。\n",
    "最常见的两种线性分类算法是 Logistic 回归（logistic regression）和线性支持向量机（linear \n",
    "support vector machine，线性 SVM），前者在 linear_model.LogisticRegression 中实现，\n",
    "后者在 svm.LinearSVC（SVC 代表支持向量分类器）中实现。虽然 LogisticRegression\n",
    "的名字中含有回归（regression），但它是一种分类算法，并不是回归算法，不应与\n",
    "LinearRegression 混淆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.3.4　朴素贝叶斯分类器\n",
    "2.3.5　决策树\n",
    "2.3.6　决策树集成\n",
    "2.3.7　核支持向量机\n",
    "2.3.8　神经网络（深度学习）\n",
    "一类被称为神经网络的算法最近以“深度学习”的名字再度流行。虽然深度学习在许多机\n",
    "器学习应用中都有巨大的潜力，但深度学习算法往往经过精确调整，只适用于特定的使\n",
    "用场景。这里只讨论一些相对简单的方法，即用于分类和回归的多层感知机（multilayer \n",
    "perceptron，MLP），它可以作为研究更复杂的深度学习方法的起点。MLP 也被称为（普\n",
    "通）前馈神经网络，有时也简称为神经网络。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
